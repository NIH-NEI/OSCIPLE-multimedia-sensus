to run a scan

* make sure msmv is running

* connect to vpn on ethernet and power (from home)

* map network drive:  smb://odapps1/Archived Images/ (z drive)
* map network drive:  smb://odapps1/OCNHO/ (o drive)

* run this:  python3 filetype-finder.py /volumes/ocnho --csvfile="odrive-{DATE}.csv" --filetypefolder="odrive-{DATE}" --maxhashreps=128
* run this:  python3 filetype-finder.py "/volumes/Archived Images" --csvfile="zdrive-{DATE}.csv" --filetypefolder="od-history-{DATE}" --maxhashreps=128

* merge all relevant csv files

* dupefinder
* dupe_dupe_checker, but on the original file?  perhaps before dupefinder?  idfk
* why is the dupefile so huge?  i may have missed something

* folder-compare





notes
- the ideal hash rep count appears to be around 512 (edit: maybe 128 will work when coupled with file size?  maybe less??)
- i think i was doing a dumb by comparing *any* hash file of different amounts of reps, but i also think this number is cool
- matching hash AND file size is probably a good idea
- adding extra reps isn't quite as time-intensive as i thought; just doing the file i/o operation generally takes more time than adding bits (unless you're scanning entire files)



python3 filetype-finder.py /volumes/ocnho --csvfile="odrive-2023-11-22.csv" --filetypefolder="odrive-2023-11-22" --maxhashreps=128
python3 filetype-finder.py "/volumes/Archived Images" --csvfile="zdrive-2023-11-22.csv" --filetypefolder="zdrive-2023-11-22" --maxhashreps=128
